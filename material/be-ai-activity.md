# Using LLM – Part 1

> [!NOTE]
> This is the first in a three-part series on using the Gemini LLM.
> Part 1 focuses on text generation with static and dynamic prompts.
> Part 2 covers structured output, and Part 3 covers analyzing images, audio, and documents.

---

## Table of Contents

* [Step 0: Prerequisites](#step-0-prerequisites)
* [Step 1: Setup Instructions](#step-1-setup-instructions)
* [Step 2: Testing the Endpoints with Postman](#step-2-testing-the-endpoints-with-postman)

  * [Task 1](#task-1)
  * [Task 2: Create a Dynamic Health Prompt](#task-2-create-a-dynamic-health-prompt)
* [Code Reference: textController1.js – Calling the Gemini LLM](#code-reference-textcontroller1js---calling-the-gemini-llm)
* [Code Reference: textController2.js – Using Dynamic Prompts](#code-reference-textcontroller2js---using-dynamic-prompts)
* [Code Reference: Model Configuration](#code-reference-model-configuration)
* [Additional Resources](#additional-resources)

---

## Step 0: Prerequisites

* **Gmail account** – Create a personal Gmail account if you do not already have one.
* **API Key** – Generate one at Google AI Studio:
  [https://aistudio.google.com/app/apikey](https://aistudio.google.com/app/apikey)
  Store the key somewhere safe.

---

## Step 1: Setup Instructions

1. **Clone the repository**

   ```bash
   git clone https://github.com/tx00-resources-en/AI-part1
   cd AI-part1
   ```

2. **Remove Git history**

   ```bash
   rm -rf .git
   ```

3. **Configure environment variables**

   * Open `.env.example`.
   * On line 1, replace the placeholder key:

     ```
     Jh6AIvfYH87KKL34KllmsHg
     ```

     with your own API key.
   * Rename `.env.example` to `.env`.

4. **Install dependencies**

   ```bash
   npm install
   ```

5. **Start the development server**

   ```bash
   npm run dev
   ```

---

## Step 2: Testing the Endpoints with Postman

### Endpoint 1 – Text Generation

* **POST** `http://localhost:4000/api/generate-text1`
* **Body (raw JSON)**:

  ```json
  {
    "prompt": "Write 3 practical tips for staying productive while working from home."
  }
  ```
* **Expected:** A text response generated by the Gemini LLM.

---

### Task 1

1. Change the static prompt text to a different prompt of your choice and test the response.
   Example:

   ```json
   {
     "prompt": "Suggest 5 creative marketing ideas for a small coffee shop."
   }
   ```

2. Document:

   * The prompt you used
   * The response you received

3. Prepare a short group presentation including:

   * The prompts you tried
   * The responses you obtained
   * Reflections on how the request body influences the LLM output and what you learned about interacting with the API

---

### Endpoint 2 – Fitness Plan (Markdown Output)

* **POST** `http://localhost:4000/api/generate-text2`
* **Body (raw JSON)**:

  ```json
  {
    "fitnessType": "strength training",
    "frequency": "4",
    "experience": "beginner",
    "goal": "build muscle and increase overall strength"
  }
  ```
* **Expected:** Response in Markdown format.

You may modify the request body to explore how the response changes.

---

## Task 2: Create a Dynamic Health Prompt

1. In your controller, destructure the request body:

   ```js
   const { age, gender, healthGoal, dietPreference, workoutDays } = req.body;
   ```

2. Check for missing fields:

   ```js
   if (!age || !gender || !healthGoal || !dietPreference || !workoutDays) {
     return res.status(400).json({ message: "All fields are required." });
   }
   ```

3. Construct a dynamic prompt using template literals:

   ```js
   const prompt = `
     I am a ${age}-year-old ${gender} aiming to ${healthGoal}.
     My diet preference is ${dietPreference}, and I can work out ${workoutDays} days per week.
     Please provide a personalized weekly health and fitness plan, including exercise types, duration, and meal suggestions.
   `;
   ```

4. Pass the prompt to your Gemini model:

   ```js
   const result = await model(prompt);
   res.json({ output: result.text });
   ```

5. In Postman, send a POST request with this JSON:

   ```json
   {
     "age": 35,
     "gender": "female",
     "healthGoal": "improve cardiovascular endurance",
     "dietPreference": "vegetarian",
     "workoutDays": 4
   }
   ```

---

## Code Reference: `textController1.js` – Calling the Gemini LLM

The simplest Gemini LLM call is shown in `textController1.js`.

1. Import the model:

   ```js
   const model = require("../services/gemini");
   ```

2. Call the model:

   ```js
   const result = await model(prompt);
   ```

3. Return the result:

   ```js
   res.json({ output: result.text });
   ```

Notes:

* `model()` returns a Promise, which is why `async/await` is used.
* The example uses a static prompt, but this can be replaced with dynamic input.

---

## Code Reference: `textController2.js` – Using Dynamic Prompts

Example from `textController2.js`:

* Destructure incoming data:

  ```js
  const { fitnessType, frequency, experience, goal } = req.body;
  ```

* Construct the prompt:

  ```js
  const prompt = `
    I am a ${experience} individual looking to focus on ${fitnessType}.
    My goal is to ${goal}, and I plan to train ${frequency} times per week.
    Provide a structured fitness guideline including recommended exercises, duration, and any diet suggestions.
  `;
  ```

---

## Code Reference: Model Configuration

The Gemini model configuration is located in `services/gemini.js`.

* On line 6, you can change the model version (examples: `gemini-2.5-flash`, `gemini-2.0-flash`).
  The default is `gemini-2.5-flash-lite` for cost efficiency.

* On line 15, the `temperature` parameter is set to `0.1`.
  This controls randomness:

  * `0.0` is deterministic
  * Higher values (0.7–1.0) generate more varied and creative responses

---

## Additional Resources

* Text Generation Docs
  [https://ai.google.dev/gemini-api/docs/text-generation](https://ai.google.dev/gemini-api/docs/text-generation)

* Document Processing Docs
  [https://ai.google.dev/gemini-api/docs/document-processing](https://ai.google.dev/gemini-api/docs/document-processing)

* Image Understanding Docs
  [https://ai.google.dev/gemini-api/docs/image-understanding](https://ai.google.dev/gemini-api/docs/image-understanding)

* Audio Processing Docs
  [https://ai.google.dev/gemini-api/docs/audio](https://ai.google.dev/gemini-api/docs/audio)

* Structured Output Docs
  [https://ai.google.dev/gemini-api/docs/structured-output](https://ai.google.dev/gemini-api/docs/structured-output)

